# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è TrOCR Evaluation

## üéØ –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
```bash
# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ (–æ–¥–∏–Ω —Ä–∞–∑)
python scripts/setup_environment.py

# 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–æ–¥–∏–Ω —Ä–∞–∑)
python scripts/download_real_iam.py

# 3. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
python scripts/run_evaluation_real.py
```

## üîß –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –û—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
```python
from trocr_evaluation import TrOCREvaluator

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
evaluator = TrOCREvaluator()

# –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
prediction = evaluator.predict_text("path/to/image.png")
print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {prediction}")
```

### –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
```python
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º
ground_truth = "—ç—Ç–∞–ª–æ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"
prediction = "—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"

wer = evaluator.calculate_wer(ground_truth, prediction)
cer = evaluator.calculate_cer(ground_truth, prediction)
accuracy = evaluator.calculate_accuracy(ground_truth, prediction)

print(f"WER: {wer:.2f}%")
print(f"CER: {cer:.2f}%")
print(f"Accuracy: {accuracy:.2f}%")
```

### –û—Ü–µ–Ω–∫–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
```python
# –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
annotations = {
    "image1.png": "—Ç–µ–∫—Å—Ç –Ω–∞ –ø–µ—Ä–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏",
    "image2.png": "—Ç–µ–∫—Å—Ç –Ω–∞ –≤—Ç–æ—Ä–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"
}

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
import json
with open("my_annotations.json", "w", encoding="utf-8") as f:
    json.dump(annotations, f, ensure_ascii=False, indent=2)

# –û—Ü–µ–Ω–∫–∞
results = evaluator.evaluate_dataset("my_images/", "my_annotations.json")
stats = evaluator.analyze_results(results)

print(f"–°—Ä–µ–¥–Ω–∏–π WER: {stats['mean_wer']:.2f}%")
```

## üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ CSV
```python
import pandas as pd

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
df = pd.read_csv("results/trocr_real_iam_evaluation.csv")

# –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
print("–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
print(df[['wer', 'cer', 'accuracy']].describe())

# –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
best_wer = df.nsmallest(5, 'wer')
print("\n–õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ WER:")
print(best_wer[['ground_truth', 'prediction', 'wer']])

# –•—É–¥—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
worst_wer = df.nlargest(5, 'wer')
print("\n–•—É–¥—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ WER:")
print(worst_wer[['ground_truth', 'prediction', 'wer']])
```

### –ê–Ω–∞–ª–∏–∑ JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
```python
import json

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
with open("results/trocr_real_iam_evaluation.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = data['statistics']
print(f"–ú–æ–¥–µ–ª—å: {data['model_name']}")
print(f"–û–±—Ä–∞–∑—Ü–æ–≤: {stats['total_samples']}")
print(f"–°—Ä–µ–¥–Ω–∏–π WER: {stats['mean_wer']:.2f}%")

# –ê–Ω–∞–ª–∏–∑ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
detailed = data['detailed_results']
perfect_matches = [r for r in detailed if r['wer'] == 0.0]
print(f"–ò–¥–µ–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(perfect_matches)}")
```

## üé® –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
```python
import matplotlib.pyplot as plt
import pandas as pd

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
df = pd.read_csv("results/trocr_real_iam_evaluation.csv")

# –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è WER
plt.figure(figsize=(10, 6))
plt.hist(df['wer'], bins=20, alpha=0.7, color='blue')
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Word Error Rate')
plt.xlabel('WER (%)')
plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
plt.savefig('custom_wer_distribution.png')
plt.show()

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ WER –∏ CER
plt.figure(figsize=(8, 6))
plt.scatter(df['wer'], df['cer'], alpha=0.6)
plt.title('WER vs CER')
plt.xlabel('Word Error Rate (%)')
plt.ylabel('Character Error Rate (%)')
plt.savefig('custom_wer_vs_cer.png')
plt.show()
```

## üîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π TrOCR
```python
models = [
    "microsoft/trocr-base-handwritten",
    "microsoft/trocr-large-handwritten",
    "microsoft/trocr-base-printed"
]

results_comparison = {}

for model_name in models:
    print(f"\n–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
    
    try:
        evaluator = TrOCREvaluator(model_name=model_name)
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö
        results = evaluator.evaluate_dataset("iam_dataset/images", "iam_dataset/kaggle_annotations.json")
        stats = evaluator.analyze_results(results)
        
        results_comparison[model_name] = {
            'wer': stats['mean_wer'],
            'cer': stats['mean_cer'],
            'accuracy': stats['mean_accuracy']
        }
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {model_name}: {e}")

# –í—ã–≤–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
print("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:")
for model, metrics in results_comparison.items():
    print(f"{model}:")
    print(f"  WER: {metrics['wer']:.2f}%")
    print(f"  CER: {metrics['cer']:.2f}%")
    print(f"  Accuracy: {metrics['accuracy']:.2f}%")
```

## üõ†Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–í —Ñ–∞–π–ª–µ `scripts/download_real_iam.py` –∏–∑–º–µ–Ω–∏—Ç–µ:
```python
# –°—Ç—Ä–æ–∫–∞ 206: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
for i, image_file in enumerate(image_files[:50]):  # –ë—ã–ª–æ 100, —Å—Ç–∞–ª–æ 50
```

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
–í —Ñ–∞–π–ª–µ `trocr_evaluation.py` –¥–æ–±–∞–≤—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
```python
def predict_text(self, image_path: str) -> str:
    # ... —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ ...
    
    with torch.no_grad():
        generated_ids = self.model.generate(
            pixel_values,
            max_length=512,        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
            num_beams=5,           # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—É—á–µ–π –¥–ª—è beam search
            early_stopping=True    # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
        )
        generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        return generated_text.strip()
```

## üìÅ –†–∞–±–æ—Ç–∞ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
```python
import os
import json
from PIL import Image

def prepare_custom_dataset(image_folder, output_folder):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    annotations = {}
    
    for filename in os.listdir(image_folder):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(image_folder, filename)
            
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            # –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–µ–Ω–∏—è —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            text = filename.split('.')[0].replace('_', ' ')
            
            annotations[image_path] = text
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    os.makedirs(output_folder, exist_ok=True)
    annotations_file = os.path.join(output_folder, "custom_annotations.json")
    
    with open(annotations_file, 'w', encoding='utf-8') as f:
        json.dump(annotations, f, ensure_ascii=False, indent=2)
    
    print(f"–ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {annotations_file}")
    return annotations_file

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
annotations_file = prepare_custom_dataset("my_images/", "custom_dataset/")

# –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
evaluator = TrOCREvaluator()
results = evaluator.evaluate_dataset("my_images/", annotations_file)
```

## üîç –û—Ç–ª–∞–¥–∫–∞ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
```python
from PIL import Image
import os

def analyze_image_quality(image_folder):
    """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    issues = []
    
    for filename in os.listdir(image_folder):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_path = os.path.join(image_folder, filename)
            
            try:
                with Image.open(image_path) as img:
                    width, height = img.size
                    
                    if width < 50 or height < 50:
                        issues.append(f"{filename}: —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({width}x{height})")
                    
                    if img.mode != 'RGB':
                        issues.append(f"{filename}: –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–∂–∏–º —Ü–≤–µ—Ç–∞ ({img.mode})")
                        
            except Exception as e:
                issues.append(f"{filename}: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ({e})")
    
    return issues

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
issues = analyze_image_quality("iam_dataset/images/")
if issues:
    print("–ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏:")
    for issue in issues:
        print(f"  - {issue}")
else:
    print("–í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–æ—Ä—è–¥–∫–µ!")
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Hugging Face TrOCR](https://huggingface.co/microsoft/trocr-base-handwritten)
- [IAM Dataset](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database)
- [JIWER Documentation](https://github.com/jitsi/jiwer)

---
*–≠—Ç–∏ –ø—Ä–∏–º–µ—Ä—ã –ø–æ–º–æ–≥—É—Ç –≤–∞–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º—É –æ—Ü–µ–Ω–∫–∏ TrOCR*
